{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness in AI: Removing word embeddings\n",
    "\n",
    "#### Kylian van Geijtenbeek, Thom Visser, Martine Toering, Iulia Ionescu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Abstract:}$ In this paper we reproduce the word embedding debiasing algorithm from Bolukbasi et al. [2]. We adapt the available implementation and extend it with their soft debiasing method. We integrate several popular benchmarks and investigate the effectiveness of the algorithm on GloVe and fastText embeddings besides the Word2vec embeddings used by Bolukbasi et al. [2]. We show that the removal of direct bias from all the different embeddings barely affects their effectiveness through a comparison of benchmark scores. However, we fail to reproduce the large scale soft debiasing results due to a lack of detail on the original implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import embetter\n",
    "import embetter.we as we\n",
    "from embetter.we import WordEmbedding\n",
    "from embetter.data import *\n",
    "\n",
    "from embetter.debias import *\n",
    "from embetter.benchmarks import Benchmark\n",
    "\n",
    "from compare_bias import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Gender Bias in word2vec, Glove and FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use one of the three different word embeddings: $\\textbf{word2vec}$ (Mikolov et al. 2013). $\\textbf{glove}$ (Pennington et al. 2014) and $\\textbf{fastText}$ (Bojanowski et al. 2016) are also available.\n",
    "\n",
    "The word2vec embedding we use is learned from a corpus of Google News articles (https://code.google.com/archive/p/word2vec/). The embeddings are 300-dimensional for 3 million words. For glove we make use of the 300-dimensional vectors trained on Common Crawl (https://nlp.stanford.edu/projects/glove/). Lastly, FastText is a word embedding from Facebook AI Research lab trained on Wikipedia corpus and Common Crawl and also consists of 300-dimensional vectors (https://fasttext.cc/docs/en/english-vectors.html).\n",
    "\n",
    "We start by loading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading word2vec_small to /Users/iulia/Documents/M_AI/FACT/FactAI/embetter/embeddings/word2vec_small.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2540/2540 [00:01<00:00, 1773.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (26423, 300)\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "Downloading word2vec_small_hard_debiased to /Users/iulia/Documents/M_AI/FACT/FactAI/embetter/embeddings/word2vec_small_hard_debiased.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2953/2953 [00:04<00:00, 716.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (26423, 300)\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "Downloading word2vec_small_soft_debiased to /Users/iulia/Documents/M_AI/FACT/FactAI/embetter/embeddings/word2vec_small_soft_debiased.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2952/2952 [00:00<00:00, 6723.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (26423, 300)\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
     ]
    }
   ],
   "source": [
    "# Load google news word2vec\n",
    "E = WordEmbedding(\"word2vec_small\")\n",
    "# Load soft debiased word2vec (for later)\n",
    "E_soft = WordEmbedding(\"word2vec_small_soft_debiased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the other embeddings can be loaded in a similar fashion, using the embedding names in the table on the GitHub Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load professions and gender related lists from Bolukbasi et al. for word2vec\n",
    "\n",
    "gender_seed, defs, equalize_pairs, profession_words = load_data(E.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define gender direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the gender direction by either PCA or by the words \"she\" and \"he\" for word2vec. \\\n",
    "The PCA method is generally more robust by incorporating all definitional word pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gender direction with the words \"she\" and \"he\" \n",
    "# v_gender = E.diff('she', 'he')\n",
    "\n",
    "# Define gender direction with PCA\n",
    "v_gender = we.doPCA(defs, E).components_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating analogies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show some of the gender analogies that we can create from the embeddings. \\\n",
    "This method is based on \"she is to X as he is to Y\" analogies, with X looping through all the words and then finding the appropriate Y. \\\n",
    "\"she\" and \"he\" are either the embeddings of these words, or the extremes of the first principal component, depending on the method used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogies gender\n",
    "a_gender = E.best_analogies_dist_thresh(v_gender, thresh=1)\n",
    "we.viz(a_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These analogies offer an insight in potential biases along the specified bias axis (in this case gender). This is useful for a qualitative analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing occupational gender bias \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection of occupations on the bias axis serves as another useful source for qualitative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analysis of extreme male and extreme female professions\n",
    "sp = E.profession_stereotypes(profession_words, v_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Comparing Bias of word2vec and FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the gender bias between word embeddings FastText and Glove. We do this by following Bolukbasi et al. approach on figure 4 in their paper. The profession words are projected onto the gender axis for two embeddings. Each datapoint represents a profession word.\n",
    "\n",
    "Below we compare the bias of Word2vec and fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_f = WordEmbedding(\"fasttext_small\")\n",
    "compare_occupational_bias(E, E_f, [\"Word2vec\", \"FastText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3 - Debiasing algorithms on word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard debiasing\n",
    "\n",
    "In hard debiasing, the gender neutral words are shifted to zero in the gender subspace (i.e. neutralized) by subtracting the projection of the neutral word embedding vector onto the gender subspace and renormalizing the resulting embedding to unit length. \n",
    "\n",
    "## Soft debiasing\n",
    "\n",
    "We adapted specifics from Manzini et al., Soft debiasing is done by solving the following optimization problem as mentioned in their paper:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\underset{T}{\\min} || (TW)^T(TW) - W^TW||^2_F + \\lambda ||(TN)^T (TB)||^2_F\n",
    "\\end{equation}\n",
    "\n",
    "where W is the matrix of all embedding vectors, N is the matrix of the embedding vectors of the gender neutral words, B is the gender subspace, and T is the debiasing transformation that minimizes the projection of the neutral words onto the gender subspace but tries to maintain the pairwise inner products between the words.\n",
    "\n",
    "This code is largely based on code from https://github.com/TManzini/DebiasMulticlassWordEmbedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard debiasing Word2vec\n",
    "Firstly, we show how to manually debias embeddings of choice. \\\n",
    "This overwrites the embeddings in the WordEmbedding object, so load the biased embeddings again in another object for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the WordEmbedding object which contains the embeddings that should be debiased.\n",
    "hard_debias(E, gender_seed, defs, equalize_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we show the effect of hard debiasing on Word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard debiased Word2vec\n",
    "# Analysis of extreme male and extreme female professions\n",
    "sp_hard_debiased = E.profession_stereotypes(profession_words, v_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogies gender\n",
    "a_gender_hard_debiased = E.best_analogies_dist_thresh(v_gender)\n",
    "we.viz(a_gender_hard_debiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package includes some basic benchmarks, which allow for easy verification of the embedding's quality before and after debiassing (RG-65, WS-353 and MSR), as well as a statistical measure of bias to quantitatively inspect the effect of debiassing (WEAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Benchmark()\n",
    "E_before = WordEmbedding(\"word2vec_small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show the benchmarks for Word2vec. \\\n",
    "When comparing the WEAT effect size, take care to use a single Benchmark object per embedding, benchmarking the biased version first. (The first bias axis is saved internally to measure bias along for subsequent embeddings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate for word2vec\n",
    "before_results = benchmark.evaluate(E_before, \"Before\")\n",
    "hard_results = benchmark.evaluate(E, \"Hard\")\n",
    "soft_results = benchmark.evaluate(E_soft, \"Soft\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of individual benchmarks can be combined into a single list and passed to the `pprint_compare` method for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_results = [before_results, hard_results, soft_results]\n",
    "benchmark.pprint_compare(w2v_results, [\"Before\", \"Hard-debiased\", \"Soft-debiased\"], \"word2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Full Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full range of experiments can be executed using the `experiments.py` file from the repository. \\\n",
    "This is best done through a terminal, to modify the behaviour using command line arguments, but its also available here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python experiments.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
