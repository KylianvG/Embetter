{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup:\n",
    "# Clone the code repository from https://github.com/tolga-b/debiaswe.git\n",
    "# mkdir debiaswe_tutorial\n",
    "# cd debiaswe_tutorial\n",
    "# git clone https://github.com/tolga-b/debiaswe.git\n",
    "\n",
    "# To reduce the time of downloading data, we provide as subset of GoogleNews-vectors in the following location:\n",
    "# https://drive.google.com/file/d/1NH6jcrg8SXbnhpIXRIXF_-KUE7wGxGaG/view?usp=sharing\n",
    "\n",
    "# For full embeddings:\n",
    "# Download embeddings at https://github.com/tolga-b/debiaswe and put them on the following directory\n",
    "# embeddings/GoogleNews-vectors-negative300-hard-debiased.bin\n",
    "# embeddings/GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import debiaswe as dwe\n",
    "import debiaswe.we as we\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.data import load_data\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Gender Bias in Word Embedding\n",
    "\n",
    "\n",
    "### Step 1: Load data\n",
    "We first load the word embedding trained on a corpus of Google News texts consisting of 3 million English words and terms. The embedding maps each word into a 300-dimension vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27014 words of dimension 300 : the, and, of, to, ..., circumscribed, whos, salvaging, anion\n",
      "Embedding shape: (27014, 300)\n",
      "<debiaswe.we.WordEmbedding object at 0x00000186DDC05E48>\n",
      "Words: 27014\n"
     ]
    }
   ],
   "source": [
    "# load google news word2vec\n",
    "E = WordEmbedding('fasttext_small')\n",
    "# E = WordEmbedding('./embeddings/GoogleNews-vectors-negative300.bin') # Not possible\n",
    "print(E)\n",
    "words = E.words\n",
    "print(\"Words:\", len(words))\n",
    "\n",
    "# load professions\n",
    "gender_specific_words, defs, _, profession_words = load_data(embed_words=E.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define gender direction\n",
    "\n",
    "We define gender direction by the direciton of she - he because they are frequent and do not have fewer alternative word senses (e.g., man can also refer to mankind). In the paper, we discuss alternative approach for defining gender direction (e.g., using PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender direction\n",
    "v_gender = E.diff('she', 'he')\n",
    "\n",
    "# Uncomment below for direction based on multiple definitional pairs\n",
    "# with open('./data/definitional_pairs.json', \"r\") as f:\n",
    "#     defs = json.load(f)\n",
    "# v_gender = we.doPCA(defs, E).components_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generating analogies of \"Man: x :: Woman : y\"\n",
    "\n",
    "We show that the word embedding model generates gender-streotypical analogy pairs. \n",
    "To generate the analogy pairs, we use the analogy score defined in our paper. This score finds word pairs that are well aligned with gender direction as well as within a short distance from each other to preserve topic consistency. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing neighbors\n"
     ]
    }
   ],
   "source": [
    "# analogies gender\n",
    "a_gender = E.best_analogies_dist_thresh(v_gender, thresh=1)\n",
    "\n",
    "# for (a,b,c) in a_gender:\n",
    "#     print(a+\"-\"+b)\n",
    "we.viz(a_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Analyzing gender bias in word vectors asscoiated with professions\n",
    "\n",
    "Next, we show that many occupations are unintendedly associated with either male of female by projecting their word vectors onto the gender dimension. \n",
    "\n",
    "The script will output the profession words sorted with respect to the projection score in the direction of gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profession analysis gender\n",
    "sp = E.profession_stereotypes(profession_words, v_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find soft debias transform using SGD\n",
    "This code is largely based on code from https://github.com/TManzini/DebiasMulticlassWordEmbedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debiaswe.debias import soft_debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss @ Epoch #0: 2403401.75\n",
      "Loss @ Epoch #100: 231891.109375\n",
      "Loss @ Epoch #200: 121064.71875\n",
      "Loss @ Epoch #300: 72851.2578125\n",
      "Loss @ Epoch #400: 47593.09765625\n",
      "Loss @ Epoch #500: 32943.98828125\n",
      "Loss @ Epoch #600: 23861.359375\n",
      "Loss @ Epoch #700: 17955.796875\n",
      "Loss @ Epoch #800: 13965.0400390625\n",
      "Loss @ Epoch #900: 11171.5673828125\n",
      "Loss @ Epoch #1000: 9148.74609375\n",
      "Loss @ Epoch #1100: 7635.443359375\n",
      "Loss @ Epoch #1200: 6468.55615234375\n",
      "Loss @ Epoch #1300: 5544.20068359375\n",
      "Loss @ Epoch #1400: 4794.7421875\n",
      "Loss @ Epoch #1500: 4174.96142578125\n",
      "Loss @ Epoch #1600: 3653.952880859375\n",
      "Loss @ Epoch #1700: 3210.147216796875\n",
      "Loss @ Epoch #1800: 2828.199462890625\n",
      "Loss @ Epoch #1900: 2502.694580078125\n",
      "Loss @ Epoch #2000: 2206.98486328125\n",
      "Loss @ Epoch #2100: 1957.8712158203125\n",
      "Loss @ Epoch #2200: 1728.5146484375\n",
      "Loss @ Epoch #2300: 1531.03125\n",
      "Loss @ Epoch #2400: 1358.1346435546875\n",
      "Loss @ Epoch #2500: 1201.07666015625\n",
      "Loss @ Epoch #2600: 1077.3358154296875\n",
      "Loss @ Epoch #2700: 957.428466796875\n",
      "Loss @ Epoch #2800: 845.5669555664062\n",
      "Loss @ Epoch #2900: 746.9635009765625\n",
      "Loss @ Epoch #3000: 677.93701171875\n",
      "Loss @ Epoch #3100: 607.6029052734375\n",
      "Loss @ Epoch #3200: 544.0581665039062\n",
      "Loss @ Epoch #3300: 488.04632568359375\n",
      "Loss @ Epoch #3400: 438.71478271484375\n",
      "Loss @ Epoch #3500: 395.8612365722656\n",
      "Loss @ Epoch #3600: 357.1643371582031\n",
      "Loss @ Epoch #3700: 320.5238342285156\n",
      "Loss @ Epoch #3800: 287.5734558105469\n",
      "Loss @ Epoch #3900: 267.272705078125\n",
      "Loss @ Epoch #4000: 241.31961059570312\n",
      "Loss @ Epoch #4100: 233.84671020507812\n",
      "Loss @ Epoch #4200: 225.00283813476562\n",
      "Loss @ Epoch #4300: 210.71011352539062\n",
      "Loss @ Epoch #4400: 197.64739990234375\n",
      "Loss @ Epoch #4500: 183.1569366455078\n",
      "Loss @ Epoch #4600: 180.86363220214844\n",
      "Loss @ Epoch #4700: 185.9498291015625\n",
      "Loss @ Epoch #4800: 186.9400634765625\n",
      "Loss @ Epoch #4900: 172.68919372558594\n",
      "Loss @ Epoch #5000: 187.0264892578125\n",
      "Loss @ Epoch #5100: 87.5610122680664\n",
      "Loss @ Epoch #5200: 86.2806625366211\n",
      "Loss @ Epoch #5300: 84.97911834716797\n",
      "Loss @ Epoch #5400: 83.64450073242188\n",
      "Loss @ Epoch #5500: 82.27537536621094\n",
      "Loss @ Epoch #5600: 80.87145233154297\n",
      "Loss @ Epoch #5700: 79.43273162841797\n",
      "Loss @ Epoch #5800: 77.95948028564453\n",
      "Loss @ Epoch #5900: 76.45233917236328\n",
      "Loss @ Epoch #6000: 74.91200256347656\n",
      "Loss @ Epoch #6100: 73.33942413330078\n",
      "Loss @ Epoch #6200: 71.73572540283203\n",
      "Loss @ Epoch #6300: 70.10211181640625\n",
      "Loss @ Epoch #6400: 68.4400634765625\n",
      "Loss @ Epoch #6500: 66.75123596191406\n",
      "Loss @ Epoch #6600: 65.03742980957031\n",
      "Loss @ Epoch #6700: 63.300498962402344\n",
      "Loss @ Epoch #6800: 61.54263687133789\n",
      "Loss @ Epoch #6900: 59.76594543457031\n",
      "Lowest loss: 57.990909576416016\n"
     ]
    }
   ],
   "source": [
    "# We set seeds in an attempt for reproducibility, but note that somehow results may still differ slightly\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "soft_debias(E, gender_specific_words, defs, epochs=7000, decrease_times=[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 27014 words to ./debiaswe/embeddings/fasttext_small_soft_debiased.txt\n"
     ]
    }
   ],
   "source": [
    "# save soft-debiased embeddings\n",
    "\n",
    "E.save('./debiaswe/embeddings/fasttext_small_soft_debiased.txt')\n",
    "# E.save('./embeddings/GoogleNews-vectors-negative300_soft_debiased.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_gender_debiased = E.best_analogies_dist_thresh(v_gender)\n",
    "we.viz(a_gender_debiased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# profession analysis gender\n",
    "sp = E.profession_stereotypes(profession_words, v_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
