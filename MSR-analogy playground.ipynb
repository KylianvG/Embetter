{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import debiaswe as dwe\n",
    "import debiaswe.we as we\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.data import load_professions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/w2v_gnews_small.txt\n",
      "(26423, 300)\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
     ]
    }
   ],
   "source": [
    "from debiaswe.benchmarks import Benchmark\n",
    "E = WordEmbedding('./embeddings/w2v_gnews_small.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded professions\n",
      "Format:\n",
      "word,\n",
      "definitional female -1.0 -> definitional male 1.0\n",
      "stereotypical female -1.0 -> stereotypical male 1.0\n",
      "+-------------------------------------------------------+\n",
      "|                    Results for test                   |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| Dataset       | Found | Not Found |       Score       |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| EN-RG-65      |   53  |     12    | 77.66555804950227 |\n",
      "| EN-WS-353-ALL |  318  |     35    | 68.82719646959825 |\n",
      "| MSR-analogy   |  5276 |    2724   | 46.79681576952237 |\n",
      "| WEAT          |   -   |     -     |     1.4845384     |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "{'EN-RG-65': [53, 12, 77.66555804950227], 'EN-WS-353-ALL': [318, 35, 68.82719646959825], 'MSR-analogy': [5276, 2724, 46.79681576952237], 'WEAT': ['-', '-', 1.4845384]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "B = Benchmark()\n",
    "print(B.evaluate(E, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded professions\n",
      "Format:\n",
      "word,\n",
      "definitional female -1.0 -> definitional male 1.0\n",
      "stereotypical female -1.0 -> stereotypical male 1.0\n"
     ]
    }
   ],
   "source": [
    "professions = load_professions()\n",
    "profession_words = [p[0] for p in professions]\n",
    "with open('./data/definitional_pairs.json', \"r\") as f:\n",
    "    defs = json.load(f)\n",
    "unzipped_defs = list(zip(*defs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_defs = np.array(unzipped_defs[0])\n",
    "male_defs = np.array(unzipped_defs[1])\n",
    "A = E.vecs[np.vectorize(E.index.__getitem__)(female_defs)]\n",
    "B = E.vecs[np.vectorize(E.index.__getitem__)(male_defs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_gender = we.doPCA(defs, E).components_[0]\n",
    "sp = sorted([(E.v(w).dot(v_gender), w) for w in profession_words])\n",
    "unzipped_sp = list(zip(*sp))\n",
    "prof_scores = np.array(unzipped_sp[0])\n",
    "sorted_profs = np.array(unzipped_sp[1])\n",
    "female_prof = sorted_profs[prof_scores>0]\n",
    "male_prof = sorted_profs[prof_scores<0]\n",
    "\n",
    "def balance_word_vectors(A, B):\n",
    "    \"\"\"\n",
    "    Balance size of two lists of word vectors by randomly deleting some vectors in larger one.\n",
    "    :param A: (len(words), dim) shaped numpy ndarrary of word vectors\n",
    "    :param B: (len(words), dim) shaped numpy ndarrary of word vectors\n",
    "    :return: tuple of two balanced word vectors\n",
    "    \"\"\"\n",
    "\n",
    "    diff = len(A) - len(B)\n",
    "\n",
    "    if diff > 0:\n",
    "        A = np.delete(A, np.random.choice(len(A), diff, 0), axis=0)\n",
    "    else:\n",
    "        B = np.delete(B, np.random.choice(len(B), -diff, 0), axis=0)\n",
    "\n",
    "    return A, B\n",
    "\n",
    "female_prof, male_prof = balance_word_vectors(female_prof, male_prof)\n",
    "\n",
    "X = E.vecs[np.vectorize(E.index.__getitem__)(np.array(female_prof))]\n",
    "Y = E.vecs[np.vectorize(E.index.__getitem__)(np.array(male_prof))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.482196\n"
     ]
    }
   ],
   "source": [
    "x_association = np.mean((X @ A.T), axis=-1) - np.mean((X @ B.T), axis=-1)\n",
    "y_association = np.mean((Y @ A.T), axis=-1) - np.mean((Y @ B.T), axis=-1)\n",
    "\n",
    "tmp1 = np.mean(x_association, axis=-1) - np.mean(y_association, axis=-1)\n",
    "tmp2 = np.std(np.concatenate((x_association, y_association), axis=0))\n",
    "\n",
    "print(tmp1/tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "0.33076844\n"
     ]
    }
   ],
   "source": [
    "from debiaswe.debias import hard_debias\n",
    "with open('./data/equalize_pairs.json', \"r\") as f:\n",
    "    equalize_pairs = json.load(f)\n",
    "with open('./data/gender_specific_seed.json', \"r\") as f:\n",
    "    gender_specific_words = json.load(f)\n",
    "hard_debias(E, gender_specific_words, defs, equalize_pairs)\n",
    "A = E.vecs[np.vectorize(E.index.__getitem__)(female_defs)]\n",
    "B = E.vecs[np.vectorize(E.index.__getitem__)(male_defs)]\n",
    "X = E.vecs[np.vectorize(E.index.__getitem__)(np.array(female_prof))]\n",
    "Y = E.vecs[np.vectorize(E.index.__getitem__)(np.array(male_prof))]\n",
    "x_association = np.mean((X @ A.T), axis=-1) - np.mean((X @ B.T), axis=-1)\n",
    "y_association = np.mean((Y @ A.T), axis=-1) - np.mean((Y @ B.T), axis=-1)\n",
    "\n",
    "tmp1 = np.mean(x_association, axis=-1) - np.mean(y_association, axis=-1)\n",
    "tmp2 = np.std(np.concatenate((x_association, y_association), axis=0))\n",
    "\n",
    "print(tmp1/tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
