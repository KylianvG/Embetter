{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: Standard Benchmarks: Coherencene\n",
    "### Using evaluation tool for word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply standard benchmarks on coherence on w2v and debiased w2v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup:\n",
    "# Clone the code repository from https://github.com/tolga-b/debiaswe.git\n",
    "# mkdir debiaswe_tutorial\n",
    "# cd debiaswe_tutorial\n",
    "# git clone https://github.com/tolga-b/debiaswe.git\n",
    "\n",
    "# To reduce the time of downloading data, we provide as subset of GoogleNews-vectors in the following location:\n",
    "# https://drive.google.com/file/d/1NH6jcrg8SXbnhpIXRIXF_-KUE7wGxGaG/view?usp=sharing\n",
    "\n",
    "# For full embeddings:\n",
    "# Download embeddings at https://github.com/tolga-b/debiaswe and put them on the following directory\n",
    "# embeddings/GoogleNews-vectors-negative300-hard-debiased.bin\n",
    "# embeddings/GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import debiaswe as dwe\n",
    "import debiaswe.we as we\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.data import load_professions\n",
    "\n",
    "import benchmarks as benchmarks\n",
    "from benchmarks.wordsim.wordsim import Wordsim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 & 2: W2vNEWS RG & WS\n",
    "\n",
    "Sources:\n",
    "\n",
    "\n",
    "RG: H. Rubenstein and J. B. Goodenough. Contextual correlates of synonymy. Communications of the ACM, 8(10):627â€“633, 1965.\n",
    "\n",
    "WS: L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman, and E. Ruppin. Placing search in context: The concept  revisited. In WWW. ACM, 2001.\n",
    "\n",
    "## Step 1: \"Before\"\n",
    "\n",
    "We first load the word embedding trained on a corpus of Google News texts consisting of 3 million English words and terms. The embedding maps each word into a 300-dimension vector. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/w2v_gnews_small.txt\n",
      "(26423, 300)\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "<debiaswe.we.WordEmbedding object at 0x7f58ae1a9210>\n",
      "Words: 26423\n"
     ]
    }
   ],
   "source": [
    "# load google news word2vec\n",
    "E = WordEmbedding('./embeddings/w2v_gnews_small.txt')\n",
    "print(E)\n",
    "words = E.words\n",
    "print(\"Words:\", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordsim benchmarks\n",
    "Source: \n",
    "\n",
    "embedding-evaluation\n",
    "\n",
    "https://github.com/k-kawakami/embedding-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_vector\n",
      "loading vector...\n",
      "loaded vector 26423 words found ..\n",
      "+----------------+-------+-----------+-------------------+\n",
      "| Dataset        | Found | Not Found |    Score (rho)    |\n",
      "+----------------+-------+-----------+-------------------+\n",
      "| EN-MTurk-771   |  759  |     12    | 67.38962809521252 |\n",
      "| EN-WS-353-REL  |  231  |     21    | 59.83270678776218 |\n",
      "| EN-MC-30       |   26  |     4     | 81.66895142451415 |\n",
      "| EN-WS-353-ALL  |  318  |     35    | 68.82719646959825 |\n",
      "| EN-MEN-TR-3k   |  2510 |    490    | 77.43180975336674 |\n",
      "| EN-MTurk-287   |  199  |     88    | 69.62042203592812 |\n",
      "| EN-WS-353-SIM  |  182  |     21    | 76.86014910176465 |\n",
      "| EN-YP-130      |  116  |     14    | 52.02603844739614 |\n",
      "| EN-RG-65       |   53  |     12    | 77.66555804950227 |\n",
      "| EN-RW-STANFORD |  460  |    1574   | 65.46249805462735 |\n",
      "+----------------+-------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "wordsim = Wordsim(\"en\")\n",
    "word2vec = wordsim.load_vector('./embeddings/w2v_gnews_small.txt')\n",
    "result = wordsim.evaluate(word2vec)\n",
    "wordsim.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 2: Debiased \n",
    "\n",
    "You can use debiaswe debias function to do the debiasing with word sets of your choosing\n",
    "\n",
    "You can leave equalize_pairs and gender_specific_words blank when coming up with your own groups. We give an example for the case of gender below for you to warm up.\n",
    "\n",
    "### Step 2a: Hard debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debiaswe.debias import debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definitional [['woman', 'man'], ['girl', 'boy'], ['she', 'he'], ['mother', 'father'], ['daughter', 'son'], ['gal', 'guy'], ['female', 'male'], ['her', 'his'], ['herself', 'himself'], ['Mary', 'John']]\n",
      "gender specific 218 ['actress', 'actresses', 'aunt', 'aunts', 'bachelor', 'ballerina', 'barbershop', 'baritone', 'beard', 'beards']\n"
     ]
    }
   ],
   "source": [
    "# Lets load some gender related word lists to help us with debiasing\n",
    "with open('./data/definitional_pairs.json', \"r\") as f:\n",
    "    defs = json.load(f)\n",
    "print(\"definitional\", defs)\n",
    "\n",
    "with open('./data/equalize_pairs.json', \"r\") as f:\n",
    "    equalize_pairs = json.load(f)\n",
    "\n",
    "with open('./data/gender_specific_seed.json', \"r\") as f:\n",
    "    gender_specific_words = json.load(f)\n",
    "print(\"gender specific\", len(gender_specific_words), gender_specific_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "{('boys', 'girls'), ('BROTHERS', 'SISTERS'), ('king', 'queen'), ('Colt', 'Filly'), ('FELLA', 'GRANNY'), ('King', 'Queen'), ('gentleman', 'lady'), ('SONS', 'DAUGHTERS'), ('wives', 'husbands'), ('Catholic_Priest', 'Nun'), ('MAN', 'WOMAN'), ('Gelding', 'Mare'), ('male', 'female'), ('HIMSELF', 'HERSELF'), ('TWIN_BROTHER', 'TWIN_SISTER'), ('Businessman', 'Businesswoman'), ('Fathers', 'Mothers'), ('fraternity', 'sorority'), ('men', 'women'), ('spokesman', 'spokeswoman'), ('BROTHER', 'SISTER'), ('Boys', 'Girls'), ('Wives', 'Husbands'), ('Schoolboy', 'Schoolgirl'), ('KINGS', 'QUEENS'), ('Grandsons', 'Granddaughters'), ('Gentleman', 'Lady'), ('Fatherhood', 'Motherhood'), ('Nephew', 'Niece'), ('Ex_Girlfriend', 'Ex_Boyfriend'), ('WIVES', 'HUSBANDS'), ('FATHER', 'MOTHER'), ('testosterone', 'estrogen'), ('PROSTATE_CANCER', 'OVARIAN_CANCER'), ('uncle', 'aunt'), ('GENTLEMAN', 'LADY'), ('FATHERHOOD', 'MOTHERHOOD'), ('SON', 'DAUGHTER'), ('dudes', 'gals'), ('Congressman', 'Congresswoman'), ('GENTLEMEN', 'LADIES'), ('kings', 'queens'), ('CONGRESSMAN', 'CONGRESSWOMAN'), ('Prostate_Cancer', 'Ovarian_Cancer'), ('his', 'her'), ('CATHOLIC_PRIEST', 'NUN'), ('nephew', 'niece'), ('PRINCE', 'PRINCESS'), ('EX_GIRLFRIEND', 'EX_BOYFRIEND'), ('Gentlemen', 'Ladies'), ('Kings', 'Queens'), ('GRANDFATHER', 'GRANDMOTHER'), ('Grandfather', 'Grandmother'), ('prince', 'princess'), ('BOY', 'GIRL'), ('COUNCILMAN', 'COUNCILWOMAN'), ('brother', 'sister'), ('grandson', 'granddaughter'), ('Twin_Brother', 'Twin_Sister'), ('prostate_cancer', 'ovarian_cancer'), ('schoolboy', 'schoolgirl'), ('Chairman', 'Chairwoman'), ('Man', 'Woman'), ('MALE', 'FEMALE'), ('His', 'Her'), ('Grandson', 'Granddaughter'), ('GELDING', 'MARE'), ('COLT', 'FILLY'), ('HIS', 'HER'), ('SCHOOLBOY', 'SCHOOLGIRL'), ('Councilman', 'Councilwoman'), ('boy', 'girl'), ('MEN', 'WOMEN'), ('FATHERS', 'MOTHERS'), ('grandpa', 'grandma'), ('chairman', 'chairwoman'), ('UNCLE', 'AUNT'), ('congressman', 'congresswoman'), ('Brother', 'Sister'), ('NEPHEW', 'NIECE'), ('Testosterone', 'Estrogen'), ('Brothers', 'Sisters'), ('Male', 'Female'), ('Dudes', 'Gals'), ('dad', 'mom'), ('HE', 'SHE'), ('father', 'mother'), ('MONASTERY', 'CONVENT'), ('Son', 'Daughter'), ('Sons', 'Daughters'), ('KING', 'QUEEN'), ('man', 'woman'), ('Uncle', 'Aunt'), ('Boy', 'Girl'), ('he', 'she'), ('himself', 'herself'), ('GRANDPA', 'GRANDMA'), ('Monastery', 'Convent'), ('Grandpa', 'Grandma'), ('fathers', 'mothers'), ('Dad', 'Mom'), ('businessman', 'businesswoman'), ('twin_brother', 'twin_sister'), ('Dads', 'Moms'), ('BOYS', 'GIRLS'), ('ex_girlfriend', 'ex_boyfriend'), ('TESTOSTERONE', 'ESTROGEN'), ('Himself', 'Herself'), ('Spokesman', 'Spokeswoman'), ('Fraternity', 'Sorority'), ('colt', 'filly'), ('fatherhood', 'motherhood'), ('Prince', 'Princess'), ('catholic_priest', 'nun'), ('DAD', 'MOM'), ('males', 'females'), ('gelding', 'mare'), ('monastery', 'convent'), ('SPOKESMAN', 'SPOKESWOMAN'), ('dads', 'moms'), ('son', 'daughter'), ('grandsons', 'granddaughters'), ('GRANDSONS', 'GRANDDAUGHTERS'), ('BUSINESSMAN', 'BUSINESSWOMAN'), ('gentlemen', 'ladies'), ('GRANDSON', 'GRANDDAUGHTER'), ('He', 'She'), ('DADS', 'MOMS'), ('Fella', 'Granny'), ('brothers', 'sisters'), ('MALES', 'FEMALES'), ('fella', 'granny'), ('DUDES', 'GALS'), ('FRATERNITY', 'SORORITY'), ('Father', 'Mother'), ('Males', 'Females'), ('grandfather', 'grandmother'), ('CHAIRMAN', 'CHAIRWOMAN'), ('councilman', 'councilwoman'), ('sons', 'daughters'), ('Men', 'Women')}\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "Saving to file...\n",
      "Wrote 26423 words to ./embeddings/w2v_gnews_debiased_small.txt\n",
      "\n",
      "\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "debias(E, gender_specific_words, defs, equalize_pairs)\n",
    "print(\"Saving to file...\")\n",
    "E.save('./embeddings/w2v_gnews_debiased_small.txt')\n",
    "print(\"\\n\\nDone!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_vector\n",
      "loading vector...\n",
      "loaded vector 26423 words found ..\n",
      "+----------------+-------+-----------+--------------------+\n",
      "| Dataset        | Found | Not Found |    Score (rho)     |\n",
      "+----------------+-------+-----------+--------------------+\n",
      "| EN-MTurk-771   |  759  |     12    | 67.51685855110493  |\n",
      "| EN-WS-353-REL  |  231  |     21    | 59.528904562337026 |\n",
      "| EN-MC-30       |   26  |     4     | 81.63475169611193  |\n",
      "| EN-WS-353-ALL  |  318  |     35    | 68.52623098234018  |\n",
      "| EN-MEN-TR-3k   |  2510 |    490    | 77.31260859852208  |\n",
      "| EN-MTurk-287   |  199  |     88    | 69.61341678196776  |\n",
      "| EN-WS-353-SIM  |  182  |     21    | 76.57438959936287  |\n",
      "| EN-YP-130      |  116  |     14    | 51.988688039001694 |\n",
      "| EN-RG-65       |   53  |     12    | 77.49622028082247  |\n",
      "| EN-RW-STANFORD |  460  |    1574   |  65.4806097177497  |\n",
      "+----------------+-------+-----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Do benchmark\n",
    "wordsim = Wordsim(\"en\")\n",
    "word2vec = wordsim.load_vector('./embeddings/w2v_gnews_debiased_small.txt')\n",
    "result = wordsim.evaluate(word2vec)\n",
    "wordsim.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
