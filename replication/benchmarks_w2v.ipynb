{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation with Standard Benchmarks: Coherence\n",
    "### Using evaluation tool for word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply standard benchmarks on coherence on w2v and debiased w2v.\n",
    "\n",
    "Sources:\n",
    "\n",
    "#### RG: H. Rubenstein and J. B. Goodenough. Contextual correlates of synonymy. Communications of the ACM, 8(10):627â€“633, 1965.\n",
    "\n",
    "####  WS: L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman, and E. Ruppin. Placing search in context: The concept  revisited. In WWW. ACM, 2001.\n",
    "\n",
    "####  Wordsim benchmarks - Code adapted from source - embedding-evaluation: https://github.com/k-kawakami/embedding-evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of GoogleNews-vectors:\n",
    "# https://drive.google.com/file/d/1NH6jcrg8SXbnhpIXRIXF_-KUE7wGxGaG/view?usp=sharing\n",
    "\n",
    "# For full embeddings:\n",
    "# Download embeddings at https://github.com/tolga-b/debiaswe and put them on the following directory\n",
    "# embeddings/GoogleNews-vectors-negative300-hard-debiased.bin\n",
    "# embeddings/GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import debiaswe as dwe\n",
    "import debiaswe.we as we\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.data import load_professions\n",
    "\n",
    "from debiaswe.benchmarks import Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small w2vNEWS set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: original word embeddings on RG & WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/w2v_gnews_small.txt\n",
      "(26423, 300)\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+-------------------------------------------------------+\n",
      "|                  Results for 'Before'                 |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| Dataset       | Found | Not Found |       Score       |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| EN-WS-353-ALL |  318  |     35    | 68.82719646959825 |\n",
      "| EN-RG-65      |   53  |     12    | 77.66555804950227 |\n",
      "| MSR-analogy   |  5276 |    2724   | 46.79681576952237 |\n",
      "+---------------+-------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# Load google news word2vec\n",
    "E = WordEmbedding('./embeddings/w2v_gnews_small.txt')\n",
    "# Evaluate\n",
    "benchmark = Benchmark()\n",
    "result_original = benchmark.evaluate(E, \"'Before', small dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2: Debiased word embeddings on RG & WS\n",
    "\n",
    "\n",
    "### Step 2a: Hard debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debiaswe.debias import hard_debias\n",
    "\n",
    "# Path for hard_debiased embedding file \n",
    "hard_embedding_file = './embeddings/w2v_gnews_small_hard_debiased.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/w2v_gnews_small_hard_debiased.txt\n",
      "(26423, 300)\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(hard_embedding_file):\n",
    "    E_hard = WordEmbedding(hard_embedding_file)\n",
    "\n",
    "else:\n",
    "    with open('./data/definitional_pairs.json', \"r\") as f:\n",
    "        defs = json.load(f)\n",
    "\n",
    "    with open('./data/equalize_pairs.json', \"r\") as f:\n",
    "        equalize_pairs = json.load(f)\n",
    "\n",
    "    with open('./data/gender_specific_seed.json', \"r\") as f:\n",
    "        gender_specific_words = json.load(f)\n",
    "        \n",
    "    hard_debias(E_hard, gender_specific_words, defs, equalize_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+--------------------------------------------------------+\n",
      "|              Results for 'Hard-debiased'               |\n",
      "+---------------+-------+-----------+--------------------+\n",
      "| Dataset       | Found | Not Found |       Score        |\n",
      "+---------------+-------+-----------+--------------------+\n",
      "| EN-WS-353-ALL |  318  |     35    | 68.52623098234018  |\n",
      "| EN-RG-65      |   53  |     12    | 77.49622028082247  |\n",
      "| MSR-analogy   |  5276 |    2724   | 46.967399545109934 |\n",
      "+---------------+-------+-----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Evaluate for hard-debiased\n",
    "result_hard_debiased = benchmark.evaluate(E_hard, \"'Hard-debiased', small dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Soft debiased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debiaswe.debias import soft_debias\n",
    "\n",
    "# Path for soft_debiased embedding file \n",
    "soft_embedding_file = './embeddings/w2v_gnews_small_soft_debiased.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/w2v_gnews_small_hard_debiased.txt\n",
      "(26423, 300)\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(hard_embedding_file):\n",
    "    E_soft = WordEmbedding(soft_embedding_file)\n",
    "else:\n",
    "    soft_debias(E_soft, gender_specific_words, defs, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+--------------------------------------------------------+\n",
      "|              Results for 'Soft-debiased'               |\n",
      "+---------------+-------+-----------+--------------------+\n",
      "| Dataset       | Found | Not Found |       Score        |\n",
      "+---------------+-------+-----------+--------------------+\n",
      "| EN-WS-353-ALL |  318  |     35    | 68.52623098234018  |\n",
      "| EN-RG-65      |   53  |     12    | 77.49622028082247  |\n",
      "| MSR-analogy   |  5276 |    2724   | 46.967399545109934 |\n",
      "+---------------+-------+-----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Evaluate for soft-debiased\n",
    "result_soft_debiased = benchmark.evaluate(E_soft, \"'Soft-debiased', small dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+\n",
      "|                         Results for small dataset                          |\n",
      "+---------------+-------------------+-------------------+--------------------+\n",
      "|     Score     |      EN-RG-65     |   EN-WS-353-ALL   |    MSR-analogy     |\n",
      "+---------------+-------------------+-------------------+--------------------+\n",
      "|     Before    | 77.66555804950227 | 68.82719646959825 | 46.79681576952237  |\n",
      "| Hard-debiased | 77.49622028082247 | 68.52623098234018 | 46.967399545109934 |\n",
      "| Soft-debiased | 77.49622028082247 | 68.52623098234018 | 46.967399545109934 |\n",
      "+---------------+-------------------+-------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "benchmark.pprint_compare([result_original, result_hard_debiased, result_soft_debiased], [\"Before\", \"Hard-debiased\", \"Soft-debiased\"], \"small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full W2vNEWS set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: original word embeddings on RG & WS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordsim benchmarks\n",
    "Code adapted from source \n",
    "\n",
    "#### embedding-evaluation: https://github.com/k-kawakami/embedding-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/GoogleNews-vectors-negative300.bin\n",
      "(3000000, 300)\n",
      "3000000 words of dimension 300 : </s>, in, for, that, ..., Bim_Skala_Bim, Mezze_Cafe, pulverizes_boulders, snowcapped_Caucasus\n",
      "3000000 words of dimension 300 : </s>, in, for, that, ..., Bim_Skala_Bim, Mezze_Cafe, pulverizes_boulders, snowcapped_Caucasus\n"
     ]
    }
   ],
   "source": [
    "# Load google news word2vec\n",
    "E = WordEmbedding('./embeddings/GoogleNews-vectors-negative300.bin')\n",
    "# Evaluate\n",
    "benchmark = Benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+-------------------------------------------------------+\n",
      "|                  Results for 'Before'                 |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| Dataset       | Found | Not Found |       Score       |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| EN-WS-353-ALL |  353  |     0     | 70.00166486272194 |\n",
      "| EN-RG-65      |   65  |     0     | 76.07828603850845 |\n",
      "| MSR-analogy   |  7022 |    978    | 47.16604955853033 |\n",
      "+---------------+-------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "result_original = benchmark.evaluate(E, \"'Before', full dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2: Debiased word embeddings on RG & WS\n",
    "\n",
    "\n",
    "### Step 2a: Hard debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debiaswe.debias import hard_debias\n",
    "\n",
    "# Path for hard_debiased embedding file \n",
    "hard_embedding_file = './embeddings/w2v_gnews_small_hard_debiased.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(hard_embedding_file):\n",
    "    E_hard = WordEmbedding(hard_embedding_file)\n",
    "\n",
    "else:\n",
    "    with open('./data/definitional_pairs.json', \"r\") as f:\n",
    "        defs = json.load(f)\n",
    "\n",
    "    with open('./data/equalize_pairs.json', \"r\") as f:\n",
    "        equalize_pairs = json.load(f)\n",
    "\n",
    "    with open('./data/gender_specific_seed.json', \"r\") as f:\n",
    "        gender_specific_words = json.load(f)\n",
    "        \n",
    "    hard_debias(E_hard, gender_specific_words, defs, equalize_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+-------------------------------------------------------+\n",
      "|              Results for 'Hard-debiased'              |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| Dataset       | Found | Not Found |       Score       |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| EN-WS-353-ALL |  353  |     0     | 69.74932474192325 |\n",
      "| EN-RG-65      |   65  |     0     | 76.50009325498166 |\n",
      "| MSR-analogy   |  7022 |    978    |  47.3939048704073 |\n",
      "+---------------+-------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# Evaluate for hard-debiased\n",
    "result_hard_debiased = benchmark.evaluate(E_hard, \"'Hard-debiased', full dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Soft debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/GoogleNews-vectors-negative300.bin\n",
      "(3000000, 300)\n",
      "3000000 words of dimension 300 : </s>, in, for, that, ..., Bim_Skala_Bim, Mezze_Cafe, pulverizes_boulders, snowcapped_Caucasus\n",
      "3000000 words of dimension 300 : </s>, in, for, that, ..., Bim_Skala_Bim, Mezze_Cafe, pulverizes_boulders, snowcapped_Caucasus\n"
     ]
    }
   ],
   "source": [
    "from debiaswe.debias import soft_debias\n",
    "\n",
    "# Path for soft_debiased embedding file \n",
    "soft_embedding_file = './embeddings/w2v_gnews_small_soft_debiased.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 36000000000000 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dbd873e9fef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoft_debias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_specific_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/FactAI/replication/debiaswe/debias.py\u001b[0m in \u001b[0;36msoft_debias\u001b[0;34m(E, gender_specific_words, defs, lamb, log, print_every, epochs, lr, gamma, decrease_times)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mgender_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;31m# lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 36000000000000 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(hard_embedding_file):\n",
    "    E_soft = WordEmbedding(soft_embedding_file)\n",
    "else:\n",
    "    soft_debias(E_soft, gender_specific_words, defs, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+-------------------------------------------------------+\n",
      "|              Results for 'Soft-debiased'              |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| Dataset       | Found | Not Found |       Score       |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| EN-WS-353-ALL |  353  |     0     | 70.00166486272194 |\n",
      "| EN-RG-65      |   65  |     0     | 76.07828603850845 |\n",
      "| MSR-analogy   |  7022 |    978    | 47.16604955853033 |\n",
      "+---------------+-------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# Evaluate for soft-debiased\n",
    "result_soft_debiased = benchmark.evaluate(E_soft, \"'Soft-debiased', full dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+\n",
      "|                          Results for full dataset                         |\n",
      "+---------------+-------------------+-------------------+-------------------+\n",
      "|     Score     |      EN-RG-65     |   EN-WS-353-ALL   |    MSR-analogy    |\n",
      "+---------------+-------------------+-------------------+-------------------+\n",
      "|     Before    | 76.07828603850845 | 70.00166486272194 | 47.16604955853033 |\n",
      "| Hard-debiased | 76.50009325498166 | 69.74932474192325 |  47.3939048704073 |\n",
      "| Soft-debiased | 76.07828603850845 | 70.00166486272194 | 47.16604955853033 |\n",
      "+---------------+-------------------+-------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "benchmark.pprint_compare([result_original, result_hard_debiased, result_soft_debiased], [\"Before\", \"Hard-debiased\", \"Soft-debiased\"], \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
