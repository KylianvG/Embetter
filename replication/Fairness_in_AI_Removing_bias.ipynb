{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness in AI: Removing word embeddings\n",
    "\n",
    "#### Kylian van Geijtenbeek, Thom Visser, Martine Toering, Iulia Ionescu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Abstract:}$ In this paper we reproduce the word embedding debiasing algo-rithm from Bolukbasi et al. [2]. We adapt their online codebase and extend it with their soft debiasing method, integrate several popular benchmarks and investigate the effectiveness of the algorithmon the newer fastText, BERT and XLNet embeddings, besides the Word2vec embeddings used by Bolukbasi et al. [2]. We show that the removal of direct bias from all the different embeddings barely affects their effectiveness through a comparison of benchmark scores. However, we fail to reproduce the large scale soft debiasing results due to a lack of detail on the original implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import debiaswe as dwe\n",
    "import debiaswe.we as we\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.data import *\n",
    "\n",
    "from debiaswe.debias import *\n",
    "from debiaswe.benchmarks import Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Gender Bias in word2vec, Glove and FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use three different word embeddings: $\\textbf{word2vec}$ (Mikolov et al. 2013), $\\textbf{glove}$ (Pennington et al. 2014) and $\\textbf{fastText}$ (Bojanowski et al. 2016).\n",
    "\n",
    "The word2vec embedding we use is learned from a corpus of Google News articles (https://code.google.com/archive/p/word2vec/). The embeddings are 300-dimensional for 3 million words. For glove we make use of the 300-dimensional vectors trained on Common Crawl (https://nlp.stanford.edu/projects/glove/). Lastly, FastText is a word embedding from Facebook AI Research lab trained on Wikipedia corpus and Common Crawl and also consists of 300-dimensional vectors.\n",
    "\n",
    "We start by loading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embedding from file: /home/martine/FactAI/replication/embeddings/w2v_gnews_small.txt\n",
      "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
      "Embedding shape: (26423, 300)\n"
     ]
    }
   ],
   "source": [
    "# TODO \n",
    "\n",
    "# Load google news word2vec\n",
    "E = WordEmbedding(\"./embeddings/w2v_gnews_small.txt\")\n",
    "# Load Glove\n",
    "# E_g = WordEmbedding(glove)\n",
    "# Load FastText \n",
    "# E = WordEmbedding(\"fasttext_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load professions and gender related lists from Bolukbasi et al. \n",
    "profession_words, defs, equalize_pairs = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define gender direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gender direction with the words \"she\" and \"he\" \n",
    "v_gender = E.diff('she', 'he')\n",
    "\n",
    "# Define gender direction with PCA\n",
    "with open('./data/definitional_pairs.json', \"r\") as f:\n",
    "    defs = json.load(f)\n",
    "    \n",
    "# Only keep definitional pairs that are present in the word embedding\n",
    "defs = [d for d in defs if d[0] in E.words and d[1] in E.words]\n",
    "\n",
    "# v_gender = we.doPCA(defs, E).components_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating analogies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogies gender\n",
    "a_gender = E.best_analogies_dist_thresh(v_gender, thresh=1)\n",
    "\n",
    "# Visualising\n",
    "we.viz(a_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing occupational gender bias \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of extreme male and extreme female professions\n",
    "sp = E.profession_stereotypes(profession_words, v_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Comparing Bias of word2vec, Glove and FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the gender bias between word embeddings FastText and Glove. We do this by following Bolukbasi et al. approach. The profession words are projected onto the gender axis for FastText and Glove. Each datapoint represents a profession word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compare word2vec to a second word embedding, change this to either fastText (E_f) or Glove (E_g)\n",
    "compare_embedding = \"fastText\"\n",
    "E_compare = E_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datapoints(sp, E, v_gender, words_set):\n",
    "    sp = sorted([(E.v(w).dot(v_gender), w) for w in profession_words if w in words_set])\n",
    "    points = [s[0] for s in sp]\n",
    "    words = [s[1] for s in sp]\n",
    "    words_sorted_ind = sorted(range(len(words)), key=lambda k: words[k])\n",
    "    datapoints =  [points[i] for i in words_sorted_ind]\n",
    "    return datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gender direction and analyse occupational bias in other word embedding\n",
    "v_gender_compare = E_compare.diff('she', 'he')\n",
    "sp_compare = E_compare.profession_stereotypes(profession_words, v_gender_compare)\n",
    "\n",
    "words_set = [s[1] for s in sp_compare]\n",
    "compare_datapoints = get_datapoints(sp_compare, E_compare, v_gender_compare, words_set)\n",
    "og_datapoints = get_datapoints(sp, E, v_gender, words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of bias of word2vec and fastText (or Glove)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(compare_datapoints, og_datapoints, s=10)\n",
    "ax.set_ylim(-0.3, 0.5)\n",
    "ax.set_xlim(-0.3, 0.5)\n",
    "plt.xlabel(\"Gender axis of {}\".format(compare_embedding), fontsize=11)\n",
    "plt.ylabel(\"Gender axis of word2vec\", fontsize=11)\n",
    "plt.title(\"Gender bias in profession words of embeddings\", pad=18, fontsize=13)\n",
    "fig.savefig(\"comparing_bias.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3 - Debiasing algorithms on word2vec, Glove and FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard debiasing\n",
    "\n",
    "In hard debiasing, the gender neutral words are shifted to zero in the gender subspace (i.e. neutralized) by subtracting the projection of the neutral word embedding vector onto the gender subspace and renormalizing the resulting embedding to unit length. \n",
    "\n",
    "## Soft debiasing\n",
    "\n",
    "We adapted specifics from Manzini et al., Soft debiasing is done by solving the following optimization problem as mentioned in their paper:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\underset{T}{\\min} || (TW)^T(TW) - W^TW||^2_F + \\lambda ||(TN)^T (TB)||^2_F\n",
    "\\end{equation}\n",
    "\n",
    "where W is the matrix of all embedding vectors, N is the matrix of the embedding vectors of the gender neutral words, B is the gender subspace, and T is the debiasing transformation that minimizes the projection of the neutral words onto the gender subspace but tries to maintain the pairwise inner products between the words.\n",
    "\n",
    "This code is largely based on code from https://github.com/TManzini/DebiasMulticlassWordEmbedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please choose one option for debiasing in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "# Change this to dataset to debias for fastText (E_f) or Glove (E_g). Default is word2vec (E)\n",
    "E_debias = E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard debias\n",
    "hard_debias(E, gender_specific_words, defs, equalize_pairs)\n",
    "\n",
    "# Soft debias\n",
    "# soft_debias(E, gender_specific_words, defs, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Save hard debiased embeddings\n",
    "E.save('./embeddings/w2v_gnews_small_hard_debiased.txt')\n",
    "\n",
    "# Save soft debiased embeddings\n",
    "# E.save('./embeddings/w2v_gnews_small_soft_debiased.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of extreme male and extreme female professions\n",
    "sp_debiased = E.profession_stereotypes(profession_words, v_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogies gender\n",
    "# a_gender_debiased = E.best_analogies_dist_thresh(v_gender)\n",
    "\n",
    "# Visualising\n",
    "# we.viz(a_gender_debiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def run_benchmark(E, embedding_name):\n",
    "    benchmark = Benchmark()\n",
    "    result_original = benchmark.evaluate(E, \"'Before', {}\".format(embedding_name))\n",
    "    E_hard = copy.deepcopy(E)\n",
    "    hard_debias(E_hard, gender_specific_words, defs, equalize_pairs)\n",
    "    result_hard_debiased = benchmark.evaluate(E_hard, \"'Hard debiased', {}\".format(embedding_name))\n",
    "    E_soft = copy.deepcopy(E) \n",
    "    soft_debias(E_soft, gender_specific_words, defs, log=False)\n",
    "    result_soft_debiased = benchmark.evaluate(E, \"'Soft debiased', {}\".format(embedding_name))\n",
    "    results = [result_original, result_hard_debiased, result_soft_debiased]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate for word2vec, Glove and FastText\n",
    "w2v_results = run_benchmark(E, \"word2vec\")\n",
    "# g_results = run_benchmark(E_g, \"Glove\")\n",
    "# f_results = run_benchmark(E_f, \"fastText\")\n",
    "\n",
    "benchmark.pprint_compare(w2v_results, [\"Before\", \"Hard-debiased\", \"Soft-debiased\"], \"word2vec\")\n",
    "# benchmark.pprint_compare(g_results, [\"Before\", \"Hard-debiased\", \"Soft-debiased\"], \"Glove\")\n",
    "# benchmark.pprint_compare(f_results, [\"Before\", \"Hard-debiased\", \"Soft-debiased\"], \"fastText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
