{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation with Standard Benchmarks: Coherence\n",
    "### Using evaluation tool for word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply standard benchmarks on coherence on w2v and debiased w2v.\n",
    "\n",
    "Sources:\n",
    "\n",
    "#### RG: H. Rubenstein and J. B. Goodenough. Contextual correlates of synonymy. Communications of the ACM, 8(10):627â€“633, 1965.\n",
    "\n",
    "####  WS: L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman, and E. Ruppin. Placing search in context: The concept  revisited. In WWW. ACM, 2001.\n",
    "\n",
    "####  Wordsim benchmarks - Code adapted from source - embedding-evaluation: https://github.com/k-kawakami/embedding-evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of GoogleNews-vectors:\n",
    "# https://drive.google.com/file/d/1NH6jcrg8SXbnhpIXRIXF_-KUE7wGxGaG/view?usp=sharing\n",
    "\n",
    "# For full embeddings:\n",
    "# Download embeddings at https://github.com/tolga-b/debiaswe and put them on the following directory\n",
    "# embeddings/GoogleNews-vectors-negative300-hard-debiased.bin\n",
    "# embeddings/GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import debiaswe as dwe\n",
    "import debiaswe.we as we\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.data import load_professions\n",
    "\n",
    "from debiaswe.benchmarks import Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: original word embeddings on RG & WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/fasttext_wiki-news-300d-1M.vec\n",
      "Got weird line 999994 300\n",
      "\n",
      "(26423, 300)\n",
      "26423 words of dimension 300 : ,, the, ., and, ..., Exclusive, Dolan, hemp, solicit\n",
      "26423 words of dimension 300 : ,, the, ., and, ..., Exclusive, Dolan, hemp, solicit\n",
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+--------------------------------------------------------+\n",
      "|             Results for 'Before', FastText             |\n",
      "+---------------+-------+-----------+--------------------+\n",
      "| Dataset       | Found | Not Found |       Score        |\n",
      "+---------------+-------+-----------+--------------------+\n",
      "| EN-WS-353-ALL |  327  |     26    | 73.31884794383402  |\n",
      "| EN-RG-65      |   47  |     18    |  81.9172617497061  |\n",
      "| MSR-analogy   |  4382 |    3618   | 54.929256047466914 |\n",
      "+---------------+-------+-----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Load FastText\n",
    "E = WordEmbedding('./embeddings/fasttext_wiki-news-300d-1M.vec', limit=26423) # limit equal to small w2v set\n",
    "# Evaluate\n",
    "benchmark = Benchmark()\n",
    "result_original = benchmark.evaluate(E, \"'Before', FastText\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2: Debiased word embeddings on RG & WS\n",
    "\n",
    "\n",
    "### Step 2a: Hard debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debiaswe.debias import hard_debias\n",
    "\n",
    "# Path for hard_debiased embedding file \n",
    "hard_embedding_file = './embeddings/fasttext_wiki-news-300d-1M_hard_debiased.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def pairs\n",
      "defs size: 10\n",
      "equalize pairs\n",
      "gender specific\n",
      "defs size: 9\n",
      "26423 words of dimension 300 : ,, the, ., and, ..., Exclusive, Dolan, hemp, solicit\n",
      "{('Councilman', 'Councilwoman'), ('Fraternity', 'Sorority'), ('Father', 'Mother'), ('BOYS', 'GIRLS'), ('MALES', 'FEMALES'), ('brothers', 'sisters'), ('men', 'women'), ('GRANDPA', 'GRANDMA'), ('fatherhood', 'motherhood'), ('King', 'Queen'), ('Prince', 'Princess'), ('GENTLEMAN', 'LADY'), ('CATHOLIC_PRIEST', 'NUN'), ('Colt', 'Filly'), ('FRATERNITY', 'SORORITY'), ('FATHERHOOD', 'MOTHERHOOD'), ('Sons', 'Daughters'), ('fraternity', 'sorority'), ('uncle', 'aunt'), ('he', 'she'), ('MONASTERY', 'CONVENT'), ('Uncle', 'Aunt'), ('boys', 'girls'), ('DUDES', 'GALS'), ('PRINCE', 'PRINCESS'), ('MAN', 'WOMAN'), ('Fella', 'Granny'), ('Twin_Brother', 'Twin_Sister'), ('SCHOOLBOY', 'SCHOOLGIRL'), ('Fatherhood', 'Motherhood'), ('Congressman', 'Congresswoman'), ('dads', 'moms'), ('Wives', 'Husbands'), ('gentleman', 'lady'), ('Dudes', 'Gals'), ('FATHER', 'MOTHER'), ('Himself', 'Herself'), ('Kings', 'Queens'), ('monastery', 'convent'), ('wives', 'husbands'), ('chairman', 'chairwoman'), ('boy', 'girl'), ('FATHERS', 'MOTHERS'), ('Catholic_Priest', 'Nun'), ('BROTHERS', 'SISTERS'), ('TWIN_BROTHER', 'TWIN_SISTER'), ('Businessman', 'Businesswoman'), ('gelding', 'mare'), ('Gentleman', 'Lady'), ('Chairman', 'Chairwoman'), ('DADS', 'MOMS'), ('son', 'daughter'), ('SONS', 'DAUGHTERS'), ('MEN', 'WOMEN'), ('KING', 'QUEEN'), ('dudes', 'gals'), ('grandson', 'granddaughter'), ('himself', 'herself'), ('catholic_priest', 'nun'), ('councilman', 'councilwoman'), ('GRANDFATHER', 'GRANDMOTHER'), ('males', 'females'), ('Males', 'Females'), ('his', 'her'), ('brother', 'sister'), ('dad', 'mom'), ('nephew', 'niece'), ('FELLA', 'GRANNY'), ('Boys', 'Girls'), ('Grandson', 'Granddaughter'), ('Testosterone', 'Estrogen'), ('Monastery', 'Convent'), ('BOY', 'GIRL'), ('His', 'Her'), ('SON', 'DAUGHTER'), ('ex_girlfriend', 'ex_boyfriend'), ('EX_GIRLFRIEND', 'EX_BOYFRIEND'), ('Grandsons', 'Granddaughters'), ('kings', 'queens'), ('grandsons', 'granddaughters'), ('BUSINESSMAN', 'BUSINESSWOMAN'), ('GRANDSON', 'GRANDDAUGHTER'), ('GENTLEMEN', 'LADIES'), ('COUNCILMAN', 'COUNCILWOMAN'), ('Nephew', 'Niece'), ('Ex_Girlfriend', 'Ex_Boyfriend'), ('sons', 'daughters'), ('prince', 'princess'), ('gentlemen', 'ladies'), ('PROSTATE_CANCER', 'OVARIAN_CANCER'), ('Spokesman', 'Spokeswoman'), ('man', 'woman'), ('Son', 'Daughter'), ('fella', 'granny'), ('CHAIRMAN', 'CHAIRWOMAN'), ('Gentlemen', 'Ladies'), ('Man', 'Woman'), ('Brothers', 'Sisters'), ('spokesman', 'spokeswoman'), ('Brother', 'Sister'), ('CONGRESSMAN', 'CONGRESSWOMAN'), ('colt', 'filly'), ('HE', 'SHE'), ('GRANDSONS', 'GRANDDAUGHTERS'), ('prostate_cancer', 'ovarian_cancer'), ('Fathers', 'Mothers'), ('KINGS', 'QUEENS'), ('NEPHEW', 'NIECE'), ('twin_brother', 'twin_sister'), ('congressman', 'congresswoman'), ('BROTHER', 'SISTER'), ('Gelding', 'Mare'), ('DAD', 'MOM'), ('king', 'queen'), ('Schoolboy', 'Schoolgirl'), ('Grandfather', 'Grandmother'), ('Dad', 'Mom'), ('male', 'female'), ('father', 'mother'), ('MALE', 'FEMALE'), ('schoolboy', 'schoolgirl'), ('fathers', 'mothers'), ('TESTOSTERONE', 'ESTROGEN'), ('Men', 'Women'), ('WIVES', 'HUSBANDS'), ('UNCLE', 'AUNT'), ('Grandpa', 'Grandma'), ('Prostate_Cancer', 'Ovarian_Cancer'), ('businessman', 'businesswoman'), ('SPOKESMAN', 'SPOKESWOMAN'), ('Dads', 'Moms'), ('Boy', 'Girl'), ('testosterone', 'estrogen'), ('HIMSELF', 'HERSELF'), ('HIS', 'HER'), ('GELDING', 'MARE'), ('grandfather', 'grandmother'), ('grandpa', 'grandma'), ('COLT', 'FILLY'), ('He', 'She'), ('Male', 'Female')}\n",
      "26423 words of dimension 300 : ,, the, ., and, ..., Exclusive, Dolan, hemp, solicit\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(hard_embedding_file):\n",
    "    E_hard = WordEmbedding(hard_embedding_file)\n",
    "\n",
    "else:\n",
    "    with open('./data/definitional_pairs.json', \"r\") as f:\n",
    "        print(\"def pairs\")\n",
    "        defs = json.load(f)\n",
    "        print(\"defs size:\", len(defs))\n",
    "\n",
    "    with open('./data/equalize_pairs.json', \"r\") as f:\n",
    "        print(\"equalize pairs\")\n",
    "        equalize_pairs = json.load(f)\n",
    "\n",
    "    with open('./data/gender_specific_seed.json', \"r\") as f:\n",
    "        print(\"gender specific\")\n",
    "        gender_specific_words = json.load(f)\n",
    "        \n",
    "    E_hard = copy.deepcopy(E)     \n",
    "    for def_pair in defs:\n",
    "        if not def_pair[0] in E_hard.words or not def_pair[1] in E_hard.words:\n",
    "            defs.remove(def_pair)\n",
    "    print(\"defs size:\", len(defs))\n",
    "    hard_debias(E_hard, gender_specific_words, defs, equalize_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+-------------------------------------------------------+\n",
      "|         Results for 'Hard-debiased', FastText         |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| Dataset       | Found | Not Found |       Score       |\n",
      "+---------------+-------+-----------+-------------------+\n",
      "| EN-WS-353-ALL |  327  |     26    | 73.33134048563385 |\n",
      "| EN-RG-65      |   47  |     18    | 81.50096849406106 |\n",
      "| MSR-analogy   |  4382 |    3618   | 55.04335919671382 |\n",
      "+---------------+-------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# Evaluate for hard-debiased\n",
    "result_hard_debiased = benchmark.evaluate(E_hard, \"'Hard-debiased', FastText\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Soft debiased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debiaswe.debias import soft_debias\n",
    "\n",
    "# Path for soft_debiased embedding file \n",
    "soft_embedding_file = './embeddings/fasttext_wiki-news-300d-1M_soft_debiased.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(hard_embedding_file):\n",
    "    E_soft = WordEmbedding(soft_embedding_file)\n",
    "else:\n",
    "    E_soft = copy.deepcopy(E)  \n",
    "    soft_debias(E_soft, gender_specific_words, defs, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 40\n",
      "Processing batch 2 of 40\n",
      "Processing batch 3 of 40\n",
      "Processing batch 4 of 40\n",
      "Processing batch 5 of 40\n",
      "Processing batch 6 of 40\n",
      "Processing batch 7 of 40\n",
      "Processing batch 8 of 40\n",
      "Processing batch 9 of 40\n",
      "Processing batch 10 of 40\n",
      "Processing batch 11 of 40\n",
      "Processing batch 12 of 40\n",
      "Processing batch 13 of 40\n",
      "Processing batch 14 of 40\n",
      "Processing batch 15 of 40\n",
      "Processing batch 16 of 40\n",
      "Processing batch 17 of 40\n",
      "Processing batch 18 of 40\n",
      "Processing batch 19 of 40\n",
      "Processing batch 20 of 40\n",
      "Processing batch 21 of 40\n",
      "Processing batch 22 of 40\n",
      "Processing batch 23 of 40\n",
      "Processing batch 24 of 40\n",
      "Processing batch 25 of 40\n",
      "Processing batch 26 of 40\n",
      "Processing batch 27 of 40\n",
      "Processing batch 28 of 40\n",
      "Processing batch 29 of 40\n",
      "Processing batch 30 of 40\n",
      "Processing batch 31 of 40\n",
      "Processing batch 32 of 40\n",
      "Processing batch 33 of 40\n",
      "Processing batch 34 of 40\n",
      "Processing batch 35 of 40\n",
      "Processing batch 36 of 40\n",
      "Processing batch 37 of 40\n",
      "Processing batch 38 of 40\n",
      "Processing batch 39 of 40\n",
      "Processing batch 40 of 40\n",
      "+--------------------------------------------------------+\n",
      "|         Results for 'Soft-debiased', FastText          |\n",
      "+---------------+-------+-----------+--------------------+\n",
      "| Dataset       | Found | Not Found |       Score        |\n",
      "+---------------+-------+-----------+--------------------+\n",
      "| EN-WS-353-ALL |  327  |     26    | 59.63640869764809  |\n",
      "| EN-RG-65      |   47  |     18    | 73.67812439839813  |\n",
      "| MSR-analogy   |  4382 |    3618   | 18.142400730260157 |\n",
      "+---------------+-------+-----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Evaluate for soft-debiased\n",
    "result_soft_debiased = benchmark.evaluate(E_soft, \"'Soft-debiased', FastText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+\n",
      "|                        Results for FastText dataset                        |\n",
      "+---------------+-------------------+-------------------+--------------------+\n",
      "|     Score     |      EN-RG-65     |   EN-WS-353-ALL   |    MSR-analogy     |\n",
      "+---------------+-------------------+-------------------+--------------------+\n",
      "|     Before    |  81.9172617497061 | 73.31884794383402 | 54.929256047466914 |\n",
      "| Hard-debiased | 81.50096849406106 | 73.33134048563385 | 55.04335919671382  |\n",
      "| Soft-debiased | 73.67812439839813 | 59.63640869764809 | 18.142400730260157 |\n",
      "+---------------+-------------------+-------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "benchmark.pprint_compare([result_original, result_hard_debiased, result_soft_debiased], [\"Before\", \"Hard-debiased\", \"Soft-debiased\"], \"FastText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
